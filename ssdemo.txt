# Elastic searchable snapshot requires enterprise license.
# Start a 30 days trial license
POST /_license/start_trial?acknowledge=true

# Register a repository
PUT _snapshot/reddot-s3-repo?pretty
  {
  "type": "s3",
  "settings": {
    "bucket": "deephub",
    "base_path": "elastic/snapshots",
    "endpoint": "192.168.170.11",
    "protocol": "http",
    "max_restore_bytes_per_sec": "1gb",
    "max_snapshot_bytes_per_sec": "200mb"
  }
}

# We can run a snapshot
PUT /_snapshot/reddot-s3-repo/demo
{
  "indices": "elasticlogs_q_01-000001",
  "include_global_state": false
}


#### Let's take a look at the Snapshots, and ILM UI


#### Full restore form a snapshot
POST /_snapshot/reddot-s3-repo/demo/_restore
{
  "indices": "elasticlogs_q_01-000001",
  "rename_pattern": "elasticlogs_q_01-000001",
  "rename_replacement": "elasticlogs_q_01-000001-fullrestore"
}

# This will fail until the shards are recovered
GET /elasticlogs_q_01-000001-fullrestore/_search

# Recovery is in progress
GET /_cat/recovery/elasticlogs_q_01-000001*/?v&h=index,time,type,stage,files_percent,bytes_recovered,bytes_percent


#### Let's take a look at FB Perf UI to confirm the snapshot/restore I/Os


#### Searchable Sanpshots for frozen tier
# We are not going to recover anymore the shard locally,
# but we will be using a cache on a frozen node which can cache data.
POST /_snapshot/reddot-s3-repo/demo/_mount?storage=shared_cache
{
  "index": "elasticlogs_q_01-000001",
  "renamed_index": "elasticlogs_q_01-000001-partialmount"
}

# We can start searching
# It's caching files in data nodes behind the scene
GET /elasticlogs_q_01-000001-partialmount/_search

# Search logs with access from Singapore
GET /elasticlogs_q_01-000001-partialmount/_search
{
  "query": {
    "match": {
      "nginx.access.geoip.country_name": "Singapore"
    }
  }
}

# Shards are being started
# We can see our shard using 0 byte on disk
GET /_cat/shards/elasticlogs_q_01-000001*/?v&h=index,shard,prirep,state,docs,store,node


#### Additional Commands ####

# Creat an index template and assosiate it with an ILM policy
PUT _index_template/ss-dailyvolume_template
{
  "index_patterns": ["elasticlogs-2023-02-*"],                 
  "template": {
    "settings": {
      "index.lifecycle.name": "ss",      
      "index.lifecycle.rollover_alias": "ss-dailyvolume"    
    }
  }
}

# Bootstrap the initial time series index with a write index alias
PUT elasticlogs-2023-02-01-000001
{
  "aliases": {
    "ss-dailyvolume": {
      "is_write_index": true
    }
  }
}

# Check lifycycle progress
GET elasticlogs-2023-02-01-*/_ilm/explain

# Check SS stat
GET /elasticlogs-2023-02-01/_searchable_snapshots/stats

# Check cache stat
GET /_searchable_snapshots/cache/stats

# Clear cache
POST /elasticlogs-2023-02-01/_searchable_snapshots/cache/clear

# Clean up
DELETE /_snapshot/reddot-s3-repo/demo
DELETE /elasticlogs_q_01-000001-fullrestore
DELETE /elasticlogs_q_01-000001-partialmount

DELETE _index_template/ss-dailyvolume_template
DELETE /elasticlogs-2023-02-01

